{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fd38a53",
   "metadata": {},
   "source": [
    "### Дополнительный инструментарий"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "848853fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Песочница\n",
    "#data0 = data.copy()\n",
    "#data0.loc[[1745,4127]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c04e006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция импорта из *.csv\n",
    "def load_from_csv(source1, source2, path2='https://code.s3.yandex.net/datasets/', sep=','):\n",
    "    \"\"\"\n",
    "        Функция организации загрузки данных в датафрейм из файла *.csv\n",
    "        на входе:\n",
    "            source1 - путь + файл *.csv на локальном компьютере\n",
    "            source2 - файл *.csv\n",
    "            path2 - путь (по умолчанию 'https://code.s3.yandex.net/datasets/')\n",
    "            sep - разделитель (по умолчанию ',')\n",
    "        на выходе:\n",
    "            df (DataFrame)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(source1, sep=sep)\n",
    "    except ValueError:\n",
    "        print('Fail - ValueError!')\n",
    "    except Exception:\n",
    "        print('Fail - загрузка из основного источника')\n",
    "        print('Попытка загрузки из резервного источника')\n",
    "        df = pd.read_csv(str(path2+source2), sep=sep)\n",
    "        print(f'OK - загрузка из резервного источника: \"{str(path2+source2)}\"')\n",
    "    else:\n",
    "        print(f'OK - загрузка из основного источника: \"{source1}\"')\n",
    "    finally:\n",
    "        print('Конец.') \n",
    "    return df\n",
    "\n",
    "#df = df.drop([''], axis=1)\n",
    "#df.drop(index=index_list, inplace=True)\n",
    "#df.to_csv('*.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b32d09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция дополнительного функционала для pd.hist() \n",
    "def grafix(df_hist, x_label='', y_label='', title=''):\n",
    "    for ax in df_hist.flatten():\n",
    "        ax.set_xlabel(x_label)\n",
    "        ax.set_ylabel(y_label)\n",
    "        ax.set_title(title)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7e80487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция вывода диаграмм рассеяния и плотности\n",
    "def plot_scatter_matrix(df, plotSize, textSize):\n",
    "    # отбросить пропуски\n",
    "    df = df.dropna()\n",
    "    # оставить числовые столбцы\n",
    "    df = df.select_dtypes(include=[np.number])\n",
    "    # оставить столбцы с заданным количеством уникальных значений\n",
    "    df = df[[col for col in df if df[col].nunique() > 1]]\n",
    "    columnNames = list(df)\n",
    "    # ограничение на количество столбцов в матрице\n",
    "    if len(columnNames) > 14:\n",
    "        columnNames = columnNames[:14]\n",
    "    df = df[columnNames]\n",
    "    ax = pd.plotting.scatter_matrix(df, alpha=0.75, figsize=[plotSize, plotSize], diagonal='kde')\n",
    "    corrs = df.corr().values\n",
    "    for i, j in zip(*plt.np.triu_indices_from(ax, k = 1)):\n",
    "        ax[i, j].annotate('Corr. coef = %.3f' % corrs[i, j], (0.8, 0.2),\n",
    "                          xycoords='axes fraction', ha='right', va='center', size=textSize)\n",
    "    plt.suptitle('Диаграммы рассеяния и плотностей', fontsize=32)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf317bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_view(df): \n",
    "    \"\"\"\n",
    "    функция для отображения общей информации\n",
    "    \n",
    "    \"\"\"\n",
    "    display(df.head(5));\n",
    "    df.info();\n",
    "    display(df.describe().style.format('{:.1f}'));\n",
    "    display(df.corr(method='spearman').style.format('{:.2f}').background_gradient('coolwarm'));\n",
    "    df.hist(figsize=(12, 15), bins=50);\n",
    "    plot_scatter_matrix(df, 30, 15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d391142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция вывода информации о столбце\n",
    "def column_value_test(ds, test='un'):\n",
    "    \"\"\"\n",
    "        Функция вывода информации о столбце\n",
    "        'un' - unique(); 'na' - isna(); 'du' - duplicated()\n",
    "    \"\"\"\n",
    "    if test == 'un':\n",
    "        return print(f'Кол-во уникальных значений в столбце: \"{ds.name}\": {len(ds.unique())}/{len(ds)}')\n",
    "    elif test == 'na':\n",
    "        return print(f'Кол-во пропущенных значений в столбце: \"{ds.name}\": {ds.isna().sum()}/{len(ds)}')\n",
    "    elif test == 'du':\n",
    "        return print(f'Кол-во дубликатов в столбце:\\n{ds.name}: {ds.duplicated().sum()}/{len(ds)}')\n",
    "    else:\n",
    "        return print(f'Error!')\n",
    "    \n",
    "#column_value_test(data.iloc[:, 0])\n",
    "#column_value_test(data.iloc[:, 0], test='na')\n",
    "#column_value_test(data.iloc[:, 0], test='du')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec4e8a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция разделеления данных на выборки: тренировочную, валидационную, тестовую\n",
    "def split_stratified_into_train_val_test(df_input, stratify_colname='y',\n",
    "                                         frac_train=0.6, frac_valid=0.2, frac_test=0.2,\n",
    "                                         random_state=12345, prnt=True):\n",
    "    '''\n",
    "    Splits a Pandas dataframe into three subsets (train, val, and test)\n",
    "    following fractional ratios provided by the user, where each subset is\n",
    "    stratified by the values in a specific column (that is, each subset has\n",
    "    the same relative frequency of the values in the column). It performs this\n",
    "    splitting by running train_test_split() twice.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df_input : Pandas dataframe\n",
    "        Input dataframe to be split.\n",
    "    stratify_colname : str\n",
    "        The name of the column that will be used for stratification. Usually\n",
    "        this column would be for the label.\n",
    "    frac_train : float\n",
    "    frac_valid : float\n",
    "    frac_test  : float\n",
    "        The ratios with which the dataframe will be split into train, val, and\n",
    "        test data. The values should be expressed as float fractions and should\n",
    "        sum to 1.0.\n",
    "    random_state : int, None, or RandomStateInstance\n",
    "        Value to be passed to train_test_split().\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X_train, X_val, X_test, y_train, y_valid, y_test:\n",
    "        Dataframes containing the six splits.\n",
    "    '''\n",
    "\n",
    "    if frac_train + frac_valid + frac_test != 1.0:\n",
    "        raise ValueError('fractions %f, %f, %f do not add up to 1.0' % \\\n",
    "                         (frac_train, frac_valid, frac_test))\n",
    "\n",
    "    if stratify_colname not in df_input.columns:\n",
    "        raise ValueError('%s is not a column in the dataframe' % (stratify_colname))\n",
    "\n",
    "    # Contains dataframe without stratify column\n",
    "    X = df_input.drop([stratify_colname], axis=1)\n",
    "    \n",
    "    # Dataframe of just the column on which to stratify\n",
    "    y = df_input[[stratify_colname]]\n",
    "\n",
    "    if frac_test > 0:\n",
    "        # Split X and y into train and temp.\n",
    "        X_train, X_temp, y_train, y_temp = train_test_split(X,\n",
    "                                                            y,\n",
    "                                                            stratify=y,\n",
    "                                                            test_size=(1.0 - frac_train),\n",
    "                                                            random_state=random_state)\n",
    "\n",
    "        # Split the temp X and y into val and test.\n",
    "        relative_frac_test = frac_test / (frac_valid + frac_test)\n",
    "        X_valid, X_test, y_valid, y_test = train_test_split(X_temp,\n",
    "                                                            y_temp,\n",
    "                                                            stratify=y_temp,\n",
    "                                                            test_size=relative_frac_test,\n",
    "                                                            random_state=random_state)\n",
    "    else:\n",
    "        X_train, X_valid, y_train, y_valid = train_test_split(X,\n",
    "                                                              y,\n",
    "                                                              #stratify=y,\n",
    "                                                              test_size=(1.0 - frac_train),\n",
    "                                                              random_state=random_state)\n",
    "        X_test = {}\n",
    "        y_test = {}\n",
    "\n",
    "    assert len(df_input) == len(X_train) + len(X_valid) + len(X_test)\n",
    "    assert len(df_input) == len(y_train) + len(y_valid) + len(y_test)\n",
    "    \n",
    "    if prnt:\n",
    "        print('dataframe:      ', df_input.shape)\n",
    "        print('features_train: ', X_train.shape)\n",
    "        print('features_valid: ', X_valid.shape)\n",
    "        if frac_test > 0:\n",
    "            print('features_test:  ', X_test.shape)\n",
    "        print('target_train:   ', y_train.shape)\n",
    "        print('target_valid:   ', y_valid.shape)\n",
    "        if frac_test > 0:\n",
    "            print('target_test:    ', y_test.shape)\n",
    "        \n",
    "    if frac_test > 0:\n",
    "        return X_train.squeeze(), X_valid.squeeze(), X_test.squeeze(),\\\n",
    "               y_train.squeeze(), y_valid.squeeze(), y_test.squeeze()\n",
    "    elif frac_test == 0:\n",
    "        return X_train.squeeze(), X_valid.squeeze(), y_train.squeeze(), y_valid.squeeze()\n",
    "    else:\n",
    "        return \"Error!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f02d1b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font size=\"4\"><b>✔️ Комментарий ревьюера</b></font>\n",
    "    <br /> \n",
    "    <font size=\"3\", color = \"black\">\n",
    "<br />    \n",
    "Жестокий кодинг )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9db95b",
   "metadata": {},
   "source": [
    "<div style=\"background: #B0E0E6; padding: 5px; border: 1px solid SteelBlue; border-radius: 5px;\">\n",
    "    <font color='4682B4'><u><b>КОММЕНТАРИЙ СТУДЕНТА</b></u></font>\n",
    "    <br />\n",
    "    <font color='4682B4'>Жизнь с учёбой ожесточили.</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67a5175",
   "metadata": {},
   "source": [
    "# Выбор локации для скважины"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a805a0",
   "metadata": {},
   "source": [
    "Допустим, вы работаете в добывающей компании «ГлавРосГосНефть». Нужно решить, где бурить новую скважину.\n",
    "\n",
    "Вам предоставлены пробы нефти в трёх регионах: в каждом 10 000 месторождений, где измерили качество нефти и объём её запасов. Постройте модель машинного обучения, которая поможет определить регион, где добыча принесёт наибольшую прибыль. Проанализируйте возможную прибыль и риски техникой *Bootstrap.*\n",
    "\n",
    "Шаги для выбора локации:\n",
    "\n",
    "- В избранном регионе ищут месторождения, для каждого определяют значения признаков;\n",
    "- Строят модель и оценивают объём запасов;\n",
    "- Выбирают месторождения с самым высокими оценками значений. Количество месторождений зависит от бюджета компании и стоимости разработки одной скважины;\n",
    "- Прибыль равна суммарной прибыли отобранных месторождений.\n",
    "\n",
    "Данные геологоразведки трёх регионов находятся в файлах: \n",
    "\n",
    "    https://code.s3.yandex.net/datasets/geo_data_0.csv\n",
    "    https://code.s3.yandex.net/datasets/geo_data_1.csv\n",
    "    https://code.s3.yandex.net/datasets/geo_data_2.csv\n",
    "    \n",
    "Условия задачи:\n",
    "\n",
    "    Для обучения модели подходит только линейная регрессия (остальные — недостаточно предсказуемые).\n",
    "    При разведке региона исследуют 500 точек, из которых с помощью машинного обучения выбирают 200 лучших для разработки.\n",
    "    Бюджет на разработку скважин в регионе — 10 млрд рублей.\n",
    "    При нынешних ценах один баррель сырья приносит 450 рублей дохода.\n",
    "    Доход с каждой единицы продукта составляет 450 тыс. рублей, поскольку объём указан в тысячах баррелей.\n",
    "    После оценки рисков нужно оставить лишь те регионы, в которых вероятность убытков меньше 2.5%.\n",
    "    Среди них выбирают регион с наибольшей средней прибылью."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad699b7e",
   "metadata": {},
   "source": [
    "**Объект исследования** — три нефтяных региона.\n",
    "\n",
    "**Цель исследования** — определить регион, где добыча принесёт наибольшую среднюю прибыль при вероятности убытков менее 2,5%.\n",
    "\n",
    "**План исследования:** \n",
    "\n",
    "    I. Загрузка и обзор данных из файлов *.csv.\n",
    "    II. Подготовка дополнительного инструментария.\n",
    "    1. Разбиение данных на обучающую и валидационную выборки (соотношение 3:1).\n",
    "    2. Обучение модели и предсказание на валидационной выборке.\n",
    "    3. Средний запас разведанного, предсказанного сырья и RMSE модели.\n",
    "    4. Подготовка к расчёту прибыли.\n",
    "    5. Разработка функции для расчёта прибыли.\n",
    "    6. Расчёт средней прибыли, 95%-й доверительного интервала и риска убытков.\n",
    "    7. Отбор моделей с вероятностью убытков менее 2,5%. Модель с наибольшим значением средней прибыли.  \n",
    "    III. Общий вывод.\n",
    "      \n",
    "**Описание данных:**\n",
    "\n",
    "Признаки:\n",
    "\n",
    "    id — уникальный идентификатор скважины\n",
    "    f0, f1, f2 — три признака точек (неважно, что они означают, но сами признаки значимы)\n",
    "\n",
    "Целевой признак:\n",
    "\n",
    "    product — объём запасов в скважине (тыс. баррелей)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5852d5e8",
   "metadata": {},
   "source": [
    "### Загрузка и подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04123eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# импорт библиотек\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.random import RandomState\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats as st\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9598789c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# настройки отображения данных\n",
    "#matplotlib.rcParams.update({'font.size': 12})\n",
    "pd.options.display.max_columns = 100\n",
    "pd.options.display.max_rows = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d7bba31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ГЛОБАЛЬНЫЕ ПЕРЕМЕННЫЕ\n",
    "# включение всех функций\n",
    "RELEASE_GLOBAL = False\n",
    "# генератор случайных чисел с ожидаемым числом\n",
    "STATE_GLOBAL = RandomState(12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f828df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# вывод предупреждений\n",
    "import warnings\n",
    "if RELEASE_GLOBAL:\n",
    "    warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a4ecd61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK - загрузка из основного источника: \"./datasets/geo_data_0.csv\"\n",
      "Конец.\n",
      "OK - загрузка из основного источника: \"./datasets/geo_data_1.csv\"\n",
      "Конец.\n",
      "OK - загрузка из основного источника: \"./datasets/geo_data_2.csv\"\n",
      "Конец.\n"
     ]
    }
   ],
   "source": [
    "# Загрузка данных\n",
    "df1 = load_from_csv(source1='./datasets/geo_data_0.csv', source2='geo_data_0.csv', sep=',')\n",
    "df2 = load_from_csv(source1='./datasets/geo_data_1.csv', source2='geo_data_1.csv', sep=',')\n",
    "df3 = load_from_csv(source1='./datasets/geo_data_2.csv', source2='geo_data_2.csv', sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63bc42e8",
   "metadata": {},
   "source": [
    "### Первый \"взгляд\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a509d5f",
   "metadata": {},
   "source": [
    "#### Первый регион"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba7a2f4c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if RELEASE_GLOBAL:\n",
    "    first_view(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2acede63",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font size=\"4\"><b>✔️ Комментарий ревьюера</b></font>\n",
    "    <br /> \n",
    "    <font size=\"3\", color = \"black\">\n",
    "<br />\n",
    "Я ревьюер простой: вижу гистограммы - пишу зелёный комментарий. А уж коэффициенты корреляции - тем более важная вещь в нашем проекте, ведь по ТЗ у нас линейная модель, нам важно не столкнуться с мультиколлинеарностью."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cfb883fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кол-во уникальных значений в столбце: \"id\": 99990/100000\n",
      "Кол-во пропущенных значений в столбце: \"id\": 0/100000\n",
      "Кол-во дубликатов в столбце:\n",
      "id: 10/100000\n",
      "Кол-во уникальных значений в столбце: \"f0\": 100000/100000\n",
      "Кол-во пропущенных значений в столбце: \"f0\": 0/100000\n",
      "Кол-во дубликатов в столбце:\n",
      "f0: 0/100000\n",
      "Кол-во уникальных значений в столбце: \"f1\": 100000/100000\n",
      "Кол-во пропущенных значений в столбце: \"f1\": 0/100000\n",
      "Кол-во дубликатов в столбце:\n",
      "f1: 0/100000\n",
      "Кол-во уникальных значений в столбце: \"f2\": 100000/100000\n",
      "Кол-во пропущенных значений в столбце: \"f2\": 0/100000\n",
      "Кол-во дубликатов в столбце:\n",
      "f2: 0/100000\n",
      "Кол-во уникальных значений в столбце: \"product\": 100000/100000\n",
      "Кол-во пропущенных значений в столбце: \"product\": 0/100000\n",
      "Кол-во дубликатов в столбце:\n",
      "product: 0/100000\n"
     ]
    }
   ],
   "source": [
    "# Проверка в столбцах на уникальные значения, пропуски, дубликаты\n",
    "for i in range(len(df1.columns)):\n",
    "    column_value_test(df1.iloc[:, i], test='un')\n",
    "    column_value_test(df1.iloc[:, i], test='na')\n",
    "    column_value_test(df1.iloc[:, i], test='du')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c6881a",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font size=\"4\"><b>✔️ Комментарий ревьюера</b></font>\n",
    "    <br /> \n",
    "    <font size=\"3\", color = \"black\">\n",
    "<br />\n",
    "Молодец, что нашёл неявные дубликаты, это далеко не все делают"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "719d0cb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7530</th>\n",
       "      <td>HZww2</td>\n",
       "      <td>1.061194</td>\n",
       "      <td>-0.373969</td>\n",
       "      <td>10.430210</td>\n",
       "      <td>158.828695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41724</th>\n",
       "      <td>bxg6G</td>\n",
       "      <td>-0.823752</td>\n",
       "      <td>0.546319</td>\n",
       "      <td>3.630479</td>\n",
       "      <td>93.007798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51970</th>\n",
       "      <td>A5aEY</td>\n",
       "      <td>-0.180335</td>\n",
       "      <td>0.935548</td>\n",
       "      <td>-2.094773</td>\n",
       "      <td>33.020205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63593</th>\n",
       "      <td>QcMuo</td>\n",
       "      <td>0.635635</td>\n",
       "      <td>-0.473422</td>\n",
       "      <td>0.862670</td>\n",
       "      <td>64.578675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66136</th>\n",
       "      <td>74z30</td>\n",
       "      <td>1.084962</td>\n",
       "      <td>-0.312358</td>\n",
       "      <td>6.990771</td>\n",
       "      <td>127.643327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69163</th>\n",
       "      <td>AGS9W</td>\n",
       "      <td>-0.933795</td>\n",
       "      <td>0.116194</td>\n",
       "      <td>-3.655896</td>\n",
       "      <td>19.230453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75715</th>\n",
       "      <td>Tdehs</td>\n",
       "      <td>0.112079</td>\n",
       "      <td>0.430296</td>\n",
       "      <td>3.218993</td>\n",
       "      <td>60.964018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90815</th>\n",
       "      <td>fiKDv</td>\n",
       "      <td>0.049883</td>\n",
       "      <td>0.841313</td>\n",
       "      <td>6.394613</td>\n",
       "      <td>137.346586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92341</th>\n",
       "      <td>TtcGQ</td>\n",
       "      <td>0.110711</td>\n",
       "      <td>1.022689</td>\n",
       "      <td>0.911381</td>\n",
       "      <td>101.318008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97785</th>\n",
       "      <td>bsk9y</td>\n",
       "      <td>0.378429</td>\n",
       "      <td>0.005837</td>\n",
       "      <td>0.160827</td>\n",
       "      <td>160.637302</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id        f0        f1         f2     product\n",
       "7530   HZww2  1.061194 -0.373969  10.430210  158.828695\n",
       "41724  bxg6G -0.823752  0.546319   3.630479   93.007798\n",
       "51970  A5aEY -0.180335  0.935548  -2.094773   33.020205\n",
       "63593  QcMuo  0.635635 -0.473422   0.862670   64.578675\n",
       "66136  74z30  1.084962 -0.312358   6.990771  127.643327\n",
       "69163  AGS9W -0.933795  0.116194  -3.655896   19.230453\n",
       "75715  Tdehs  0.112079  0.430296   3.218993   60.964018\n",
       "90815  fiKDv  0.049883  0.841313   6.394613  137.346586\n",
       "92341  TtcGQ  0.110711  1.022689   0.911381  101.318008\n",
       "97785  bsk9y  0.378429  0.005837   0.160827  160.637302"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# дубли в столбце 'id'\n",
    "df1[df1['id'].duplicated()].head(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e3ce7515",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "product\n",
       "0.000000      1\n",
       "0.004022      1\n",
       "0.006114      1\n",
       "0.009428      1\n",
       "0.021781      1\n",
       "             ..\n",
       "185.352015    1\n",
       "185.354980    1\n",
       "185.355615    1\n",
       "185.362690    1\n",
       "185.364347    1\n",
       "Length: 100000, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.value_counts('product', normalize=False, sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85538fd2",
   "metadata": {},
   "source": [
    "Наблюдения:\n",
    "\n",
    "- признаки 'f0' и 'f1' имеют вид сложения нескольких нормальных распределений\n",
    "- корреляция между 'f0' и 'f1' около 0,5; eсть корреляции с 'product'\n",
    "- признак 'f2' имеет нормальное распределение\n",
    "- признак 'product' имеет распределение смешанного вида (нормальное и равномерное) аналогичное с df3\n",
    "- корреляция 'f2' c 'product' около 0,5\n",
    "- дубли в столбце 'id', возможно, возникли в результае коллизий хеш-функции"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238e47e1",
   "metadata": {},
   "source": [
    "#### Второй регион"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cca00be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RELEASE_GLOBAL:\n",
    "    first_view(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e204ed43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кол-во уникальных значений в столбце: \"id\": 99996/100000\n",
      "Кол-во пропущенных значений в столбце: \"id\": 0/100000\n",
      "Кол-во дубликатов в столбце:\n",
      "id: 4/100000\n",
      "Кол-во уникальных значений в столбце: \"f0\": 100000/100000\n",
      "Кол-во пропущенных значений в столбце: \"f0\": 0/100000\n",
      "Кол-во дубликатов в столбце:\n",
      "f0: 0/100000\n",
      "Кол-во уникальных значений в столбце: \"f1\": 100000/100000\n",
      "Кол-во пропущенных значений в столбце: \"f1\": 0/100000\n",
      "Кол-во дубликатов в столбце:\n",
      "f1: 0/100000\n",
      "Кол-во уникальных значений в столбце: \"f2\": 100000/100000\n",
      "Кол-во пропущенных значений в столбце: \"f2\": 0/100000\n",
      "Кол-во дубликатов в столбце:\n",
      "f2: 0/100000\n",
      "Кол-во уникальных значений в столбце: \"product\": 12/100000\n",
      "Кол-во пропущенных значений в столбце: \"product\": 0/100000\n",
      "Кол-во дубликатов в столбце:\n",
      "product: 99988/100000\n"
     ]
    }
   ],
   "source": [
    "# Проверка в столбцах на уникальные значения, пропуски, дубликаты\n",
    "for i in range(len(df2.columns)):\n",
    "    column_value_test(df2.iloc[:, i], test='un')\n",
    "    column_value_test(df2.iloc[:, i], test='na')\n",
    "    column_value_test(df2.iloc[:, i], test='du')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f46fde0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41906</th>\n",
       "      <td>LHZR0</td>\n",
       "      <td>-8.989672</td>\n",
       "      <td>-4.286607</td>\n",
       "      <td>2.009139</td>\n",
       "      <td>57.085625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82178</th>\n",
       "      <td>bfPNe</td>\n",
       "      <td>-6.202799</td>\n",
       "      <td>-4.820045</td>\n",
       "      <td>2.995107</td>\n",
       "      <td>84.038886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82873</th>\n",
       "      <td>wt4Uk</td>\n",
       "      <td>10.259972</td>\n",
       "      <td>-9.376355</td>\n",
       "      <td>4.994297</td>\n",
       "      <td>134.766305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84461</th>\n",
       "      <td>5ltQ6</td>\n",
       "      <td>18.213839</td>\n",
       "      <td>2.191999</td>\n",
       "      <td>3.993869</td>\n",
       "      <td>107.813044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id         f0        f1        f2     product\n",
       "41906  LHZR0  -8.989672 -4.286607  2.009139   57.085625\n",
       "82178  bfPNe  -6.202799 -4.820045  2.995107   84.038886\n",
       "82873  wt4Uk  10.259972 -9.376355  4.994297  134.766305\n",
       "84461  5ltQ6  18.213839  2.191999  3.993869  107.813044"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# дубли в столбце 'id'\n",
    "df2[df2['id'].duplicated()].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "70edf6c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# дубликаты в строках с выборочными столбцами\n",
    "df2[['id', 'product']].duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9840a2b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "product\n",
       "0.000000      8235\n",
       "3.179103      8337\n",
       "26.953261     8468\n",
       "30.132364     8306\n",
       "53.906522     8472\n",
       "57.085625     8390\n",
       "80.859783     8320\n",
       "84.038886     8431\n",
       "107.813044    8201\n",
       "110.992147    8303\n",
       "134.766305    8304\n",
       "137.945408    8233\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# перечень категорий в признаке 'product'\n",
    "df2.value_counts('product', normalize=False, sort=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "810e1a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# разделим на два явных подмножества\n",
    "indexes = df2.value_counts('product', normalize=False, sort=False).index\n",
    "indexes1 = indexes[[0,2,4,6,8,10]]  \n",
    "indexes2 = indexes[[1,3,5,7,9,11]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a2575496",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "product\n",
       "0.000000      8235\n",
       "26.953261     8468\n",
       "53.906522     8472\n",
       "80.859783     8320\n",
       "107.813044    8201\n",
       "134.766305    8304\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_1 = df2.query('product in @indexes1')\n",
    "df2_1.value_counts('product', normalize=False, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "032541ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "product\n",
       "3.179103      8337\n",
       "30.132364     8306\n",
       "57.085625     8390\n",
       "84.038886     8431\n",
       "110.992147    8303\n",
       "137.945408    8233\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_2 = df2.query('product in @indexes2')\n",
    "df2_2.value_counts('product', normalize=False, sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa73a49",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<font size=\"4\"><b>⚠️ Комментарий ревьюера</b></font>\n",
    "    <br /> \n",
    "    <font size=\"3\", color = \"black\">\n",
    "<br />\n",
    "<u>Контрольный вопрос:</u>\n",
    "\n",
    "Не понял логику этого разделения. Можешь, пожалуйста, пояснить?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48789d63",
   "metadata": {},
   "source": [
    "<div style=\"background: #B0E0E6; padding: 5px; border: 1px solid SteelBlue; border-radius: 5px;\">\n",
    "    <font color='4682B4'><u><b>КОММЕНТАРИЙ СТУДЕНТА</b></u></font>\n",
    "    <br />\n",
    "    <font color='4682B4'>Обратил внимание, что данные по второму региону состоят из двух легко разделяемых и одинаковых множеств. Разделил. Паразитные корреляции исчезли. RMSE стал ещё меньше. Во втором множестве оказались все 200 самых прибыльных скважин, что упрощает расчёты без потери соответствия требованиям задания. Если скважины второго подмножества локализованы (допускаю), то сразу понятно в какой части региона добыча более прибыльна и первое подмножество можно не рассматривать. Т.е. можно упростить, улучшить расчёты и, возможно, сразу определить более перспективный для добычи район региона №2.</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19890c6c",
   "metadata": {},
   "source": [
    "##### Подмножество 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c25d4863",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RELEASE_GLOBAL:\n",
    "    first_view(df2_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594002ef",
   "metadata": {},
   "source": [
    "##### Подмножество 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d857c928",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RELEASE_GLOBAL:\n",
    "    first_view(df2_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba85341a",
   "metadata": {},
   "source": [
    "Наблюдение:\n",
    "\n",
    "- датафрейм df2 состоит из двух равных подмножеств, на которые легко разделить по смежным категориям признака 'product'\n",
    "- после разделения:\n",
    "    - у признака 'f0' нормальное распределение\n",
    "    - исчезли корреляции между 'f0', 'f1', 'product'\n",
    "- у признака 'f1' нормальное распределение\n",
    "- признак 'f2' имеет интервальный характер, а укрупнённо имеет категориальный и равномерное распределение\n",
    "- признак 'product' имеет не интервальный, а категориальный характер и равномерное распределение\n",
    "- корреляция 'f2' c 'product' около 1\n",
    "- дубли в столбце 'id', возможно, возникли из-за коллизий фарш-функции"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b935ec0a",
   "metadata": {},
   "source": [
    "#### Третий регион"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "94bcad0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RELEASE_GLOBAL:\n",
    "    first_view(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5fcfb5ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кол-во уникальных значений в столбце: \"id\": 99996/100000\n",
      "Кол-во пропущенных значений в столбце: \"id\": 0/100000\n",
      "Кол-во дубликатов в столбце:\n",
      "id: 4/100000\n",
      "Кол-во уникальных значений в столбце: \"f0\": 100000/100000\n",
      "Кол-во пропущенных значений в столбце: \"f0\": 0/100000\n",
      "Кол-во дубликатов в столбце:\n",
      "f0: 0/100000\n",
      "Кол-во уникальных значений в столбце: \"f1\": 100000/100000\n",
      "Кол-во пропущенных значений в столбце: \"f1\": 0/100000\n",
      "Кол-во дубликатов в столбце:\n",
      "f1: 0/100000\n",
      "Кол-во уникальных значений в столбце: \"f2\": 100000/100000\n",
      "Кол-во пропущенных значений в столбце: \"f2\": 0/100000\n",
      "Кол-во дубликатов в столбце:\n",
      "f2: 0/100000\n",
      "Кол-во уникальных значений в столбце: \"product\": 100000/100000\n",
      "Кол-во пропущенных значений в столбце: \"product\": 0/100000\n",
      "Кол-во дубликатов в столбце:\n",
      "product: 0/100000\n"
     ]
    }
   ],
   "source": [
    "# Проверка в столбцах на уникальные значения, пропуски, дубликаты\n",
    "for i in range(len(df3.columns)):\n",
    "    column_value_test(df3.iloc[:, i], test='un')\n",
    "    column_value_test(df3.iloc[:, i], test='na')\n",
    "    column_value_test(df3.iloc[:, i], test='du')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6c3758b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43233</th>\n",
       "      <td>xCHr8</td>\n",
       "      <td>-0.847066</td>\n",
       "      <td>2.101796</td>\n",
       "      <td>5.597130</td>\n",
       "      <td>184.388641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49564</th>\n",
       "      <td>VF7Jo</td>\n",
       "      <td>-0.883115</td>\n",
       "      <td>0.560537</td>\n",
       "      <td>0.723601</td>\n",
       "      <td>136.233420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55967</th>\n",
       "      <td>KUPhW</td>\n",
       "      <td>1.211150</td>\n",
       "      <td>3.176408</td>\n",
       "      <td>5.543540</td>\n",
       "      <td>132.831802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95090</th>\n",
       "      <td>Vcm5J</td>\n",
       "      <td>2.587702</td>\n",
       "      <td>1.986875</td>\n",
       "      <td>2.482245</td>\n",
       "      <td>92.327572</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id        f0        f1        f2     product\n",
       "43233  xCHr8 -0.847066  2.101796  5.597130  184.388641\n",
       "49564  VF7Jo -0.883115  0.560537  0.723601  136.233420\n",
       "55967  KUPhW  1.211150  3.176408  5.543540  132.831802\n",
       "95090  Vcm5J  2.587702  1.986875  2.482245   92.327572"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# дубли в столбце 'id'\n",
    "df3[df3['id'].duplicated()].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "734175d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "product\n",
       "0.000000      1\n",
       "0.004606      1\n",
       "0.009204      1\n",
       "0.009761      1\n",
       "0.014039      1\n",
       "             ..\n",
       "190.010029    1\n",
       "190.010982    1\n",
       "190.011722    1\n",
       "190.013589    1\n",
       "190.029838    1\n",
       "Length: 100000, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.value_counts('product', normalize=False, sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1b8c6a",
   "metadata": {},
   "source": [
    "Наблюдение:\n",
    "\n",
    "- признаки 'f0', 'f1', 'f2' имеют нормальное распределение. Корреляции между собой нет\n",
    "- признак 'product' имеет распределение смешанного вида (нормальное и равномерное)\n",
    "- корреляция 'f2' и 'product' около 0,5\n",
    "- дубли в столбце 'id', возможно, возникли в результате коллизий хеш-функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a4231bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# удаление признака 'id' из-за ненадобности\n",
    "df1 = df1.drop('id', axis= 1)\n",
    "df2 = df2.drop('id', axis= 1)\n",
    "df3 = df3.drop('id', axis= 1)\n",
    "\n",
    "df2_1 = df2_1.drop('id', axis= 1)\n",
    "df2_2 = df2_2.drop('id', axis= 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5941793",
   "metadata": {},
   "source": [
    "#### Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0710bd8b",
   "metadata": {},
   "source": [
    "**Краткое описание:**\n",
    "\n",
    "    - файлы данных:\n",
    "        - 'https://code.s3.yandex.net/datasets/geo_data_0.csv'\n",
    "        - 'https://code.s3.yandex.net/datasets/geo_data_1.csv'\n",
    "        - 'https://code.s3.yandex.net/datasets/geo_data_2.csv'\n",
    "    - в качестве разделителя в csv файле применён знак табуляции (',')\n",
    "    - размерность: 5 столбцов на 100000 строк\n",
    "    - типы данных: float64(4), object(1)\n",
    "\n",
    "**Описание типов и распределеления данных:**\n",
    "\n",
    "- geo_data_0.csv:\n",
    "\t- id      — [object]  — \n",
    "    - f0      — [float64] — вид сложения нескольких нормальных распределений\n",
    "    - f1      — [float64] — вид сложения нескольких нормальных распределений\n",
    "    - f2      — [float64] — нормальное распределение\n",
    "    - product — [float64] — распределение смешанного вида (нормальное и равномерное)\n",
    "    \n",
    "    - корреляция между 'f0' и 'f1' около 0,5; eсть корреляции с 'product'\n",
    "    - корреляция 'f2' c 'product' около 0,5\n",
    "    \n",
    "- geo_data_1.csv:\n",
    "\t- id      — [object]  — \n",
    "    - f0      — [float64] — имеет вид сложения двух нормальных распределений\n",
    "    - f1      — [float64] — нормальное распределение\n",
    "    - f2      — [float64] — укрупнённо принимает категориальный характер и равномерное распределение\n",
    "    - product — [float64] — имеет не интервальный, а категориальный характер и равномерное распределение\n",
    "    \n",
    "    - датафрейм df2 легко можно разделить на два подмножества по смежным категориям признака 'product'\n",
    "    - после разделения:\n",
    "        - у признака 'f0' нормальное распределение\n",
    "        - исчезают корреляции между 'f0', 'f1', 'product'\n",
    "    - корреляция 'f2' c 'product' около 1\n",
    "    \n",
    "- geo_data_2.csv:\n",
    "\t- id      — [object]  — \n",
    "    - f0      — [float64] — нормальное распределение\n",
    "    - f1      — [float64] — нормальное распределение\n",
    "    - f2      — [float64] — нормальное распределение\n",
    "    - product — [float64] — распределение смешанного вида (нормальное и равномерное)\n",
    "    \n",
    "    - корреляция 'f2' c 'product' около 0,5\n",
    "\n",
    "**Пропуски, аномалии, дубликаты:**\n",
    "\n",
    "количество пропусков:\n",
    "\n",
    "    - все признаки   — 0/100000 \n",
    "    \n",
    "аномалии:\n",
    "    \n",
    "    - все признаки   — 0/100000 \n",
    "\n",
    "количество уникальных значений в столбцах:\n",
    "\n",
    "    - id      — 99990/100000 (df1), 99996/100000 (df2, df3)\n",
    "    - f0      — 100000/100000\n",
    "    - f1      — 100000/100000\n",
    "    - f2      — 100000/100000\n",
    "    - product — 100000/100000 (df1, df3), 12/100000 (df2)\n",
    "    \n",
    "количество дубликатов между столбцами:\n",
    "\n",
    "    - не проверял\n",
    "\n",
    "количество дубликатов строк с выборочными столбцами:\n",
    "\n",
    "    - id, product: 0\n",
    "\n",
    "**Прочее**:\n",
    "\n",
    "    - дубли в столбце 'id', возможно, возникли в результае коллизий фарш-функции"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e838f2",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font size=\"4\"><b>✔️ Комментарий ревьюера</b></font>\n",
    "    <br /> \n",
    "    <font size=\"3\", color = \"black\">\n",
    "<br />\n",
    "Здорово, что прежде чем обучать модели анализируешь данные, и делаешь это весьма добротно"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac54adc",
   "metadata": {},
   "source": [
    "## Обучение и проверка модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b1b17280",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_oil(df, colname, title=''):     \n",
    "    features_train, features_valid, target_train, target_valid = \\\n",
    "    split_stratified_into_train_val_test(df, stratify_colname=colname,\n",
    "                                         frac_train=0.75, frac_valid=0.25, frac_test=0.0,\n",
    "                                         random_state=12345)\n",
    "    params = {}\n",
    "    lr = LinearRegression()\n",
    "    #gscv_lr = GridSearchCV(lr, param_grid = params, n_jobs = -1)\n",
    "    model = lr.fit(features_train, target_train)\n",
    "    predict = pd.Series(model.predict(features_valid))\n",
    "    \n",
    "    print()\n",
    "    print(f'== {title} ==')\n",
    "    print('Среднее значение разведанных запасов на скважину, тыс.бар.:  ', round(target_valid.mean(), 3))\n",
    "    print('Среднее значение предсказанных запасов на скважину, тыс.бар: ', round(predict.mean(), 3))\n",
    "    print('Среднеквадратичная ошибка RMSE: ', mean_squared_error(target_valid, predict) ** 0.5)\n",
    "    print('\\n')\n",
    "    \n",
    "    return predict, target_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2aa7e98",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font size=\"4\"><b>✔️ Комментарий ревьюера</b></font>\n",
    "    <br /> \n",
    "    <font size=\"3\", color = \"black\">\n",
    "<br />\n",
    "Молодец, что оформил в виде функции. Это в принципе правильный подход, повышающий простоту использования и поддержки кода, а когда вся работа по сути - это повторение однотипных действия над схожими датасетами, то это особенно актуально."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46baaed3",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<font size=\"4\">🍕<b> Комментарий ревьюера</b></font>\n",
    "    <br /> \n",
    "    <font size=\"3\", color = \"black\">\n",
    "<br />\n",
    "Настоятельно тебе рекомендую рандом стейт (и другие глобальные константы) в начале работы сохранять в отдельную переменную и оперировать дальше ей. Иногда бывает нужно провести эксперимент с другим рандомом и менять по коду во всех местах где он испоьзуется явно хуже, чем одну переменную в начале поменять."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bee34b",
   "metadata": {},
   "source": [
    "<div style=\"background: #B0E0E6; padding: 5px; border: 1px solid SteelBlue; border-radius: 5px;\">\n",
    "    <font color='4682B4'><u><b>КОММЕНТАРИЙ СТУДЕНТА</b></u></font>\n",
    "    <br />\n",
    "    <font color='4682B4'>Сделал.</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6867d986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataframe:       (100000, 4)\n",
      "features_train:  (75000, 3)\n",
      "features_valid:  (25000, 3)\n",
      "target_train:    (75000, 1)\n",
      "target_valid:    (25000, 1)\n",
      "\n",
      "== Регион № 1 ==\n",
      "Среднее значение разведанных запасов на скважину, тыс.бар.:   92.079\n",
      "Среднее значение предсказанных запасов на скважину, тыс.бар:  92.593\n",
      "Среднеквадратичная ошибка RMSE:  37.5794217150813\n",
      "\n",
      "\n",
      "dataframe:       (100000, 4)\n",
      "features_train:  (75000, 3)\n",
      "features_valid:  (25000, 3)\n",
      "target_train:    (75000, 1)\n",
      "target_valid:    (25000, 1)\n",
      "\n",
      "== Регион № 2 ==\n",
      "Среднее значение разведанных запасов на скважину, тыс.бар.:   68.723\n",
      "Среднее значение предсказанных запасов на скважину, тыс.бар:  68.729\n",
      "Среднеквадратичная ошибка RMSE:  0.893099286775617\n",
      "\n",
      "\n",
      "dataframe:       (100000, 4)\n",
      "features_train:  (75000, 3)\n",
      "features_valid:  (25000, 3)\n",
      "target_train:    (75000, 1)\n",
      "target_valid:    (25000, 1)\n",
      "\n",
      "== Регион № 3 ==\n",
      "Среднее значение разведанных запасов на скважину, тыс.бар.:   94.884\n",
      "Среднее значение предсказанных запасов на скважину, тыс.бар:  94.965\n",
      "Среднеквадратичная ошибка RMSE:  40.02970873393434\n",
      "\n",
      "\n",
      "dataframe:       (50000, 4)\n",
      "features_train:  (37500, 3)\n",
      "features_valid:  (12500, 3)\n",
      "target_train:    (37500, 1)\n",
      "target_valid:    (12500, 1)\n",
      "\n",
      "== Регион № 2.1 ==\n",
      "Среднее значение разведанных запасов на скважину, тыс.бар.:   67.346\n",
      "Среднее значение предсказанных запасов на скважину, тыс.бар:  67.347\n",
      "Среднеквадратичная ошибка RMSE:  0.13376884129078812\n",
      "\n",
      "\n",
      "dataframe:       (50000, 4)\n",
      "features_train:  (37500, 3)\n",
      "features_valid:  (12500, 3)\n",
      "target_train:    (37500, 1)\n",
      "target_valid:    (12500, 1)\n",
      "\n",
      "== Регион № 2.2 ==\n",
      "Среднее значение разведанных запасов на скважину, тыс.бар.:   69.706\n",
      "Среднее значение предсказанных запасов на скважину, тыс.бар:  69.705\n",
      "Среднеквадратичная ошибка RMSE:  0.13507895709908402\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# предикция запасов и разведанные запасы\n",
    "predict1, target1 = predict_oil(df1, colname='product', title='Регион № 1')\n",
    "predict2, target2 = predict_oil(df2, colname='product', title='Регион № 2')\n",
    "predict3, target3 = predict_oil(df3, colname='product', title='Регион № 3')\n",
    "predict2_1, target2_1 = predict_oil(df2_1, colname='product', title='Регион № 2.1')\n",
    "predict2_2, target2_2 = predict_oil(df2_2, colname='product', title='Регион № 2.2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d01b34",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font size=\"4\"><b>✔️ Комментарий ревьюера</b></font>\n",
    "    <br /> \n",
    "    <font size=\"3\", color = \"black\">\n",
    "<br />\n",
    "Получены адекватные модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06069dfa",
   "metadata": {},
   "source": [
    "Наблюдение:\n",
    "\n",
    "- в регионе №3 наибольшие запасы, за ним регион №1 с небольшим отставанием\n",
    "- для регионов №1 и №3 самые большие значения среднеквадратичной ошибки RMSE: 37.6 и 40\n",
    "- меньше всего запасов в регионе №2, но среднеквадратичная ошибка менее 1\n",
    "- а у подмножеств №2.1 и №2.2 среднеквадратичная ошибка менее 0,14 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717396f3",
   "metadata": {},
   "source": [
    "## Подготовка к расчёту прибыли"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ddf3d5e",
   "metadata": {},
   "source": [
    "Все ключевые значения для расчётов сохраним в отдельных переменных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8b2708d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUDGET_REGION = 10*(10**9)                     # 10 млрд.р. - бюджет разработки скважин в выбранном регионе\n",
    "TESTED_WELLS = 500                             # количество разведочных скважин\n",
    "SELECTED_WELLS = 200                           # количество скважин выбранных для разработки\n",
    "BUDGET_PER_WELL = BUDGET_REGION/SELECTED_WELLS # бюджет на 1 скважину\n",
    "REVENUE_BAR = 450                              # доход с каждого барреля\n",
    "REVENUE_PRODUCT = REVENUE_BAR*(10**3)          # доход с каждой единицы продукта (1000 баррелей)\n",
    "MAX_THRESHOLD_LOSS_PROBA = 0.025               # 2,5% - максимальный порог вероятности убытков\n",
    "CONFIDENCE_LEVEL = 0.95                        # 0,95 - уровень доверия (1-уровень значимости)\n",
    "QUANTILE_LOW = 0.025                           # 0,025 квантиль\n",
    "QUANTILE_HIGH = 0.975                          # 0,975 квантиль\n",
    "\n",
    "# требуемое количество нефти (тыс.бар.) с одной скважины для окупаемости \n",
    "MIN_VALUE_PRODUCT = BUDGET_PER_WELL / REVENUE_PRODUCT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d979eb",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font size=\"4\"><b>✔️ Комментарий ревьюера</b></font>\n",
    "    <br /> \n",
    "    <font size=\"3\", color = \"black\">\n",
    "<br />\n",
    "Здорово, что знаешь, что константы принято называть КАПСОМ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bbcf60",
   "metadata": {},
   "source": [
    "### Расчёт и сравнение достаточного объёма сырья для безубыточной разработки новой скважины"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b3d98a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Затраты на скважину, млн.руб.: 50.0\n",
      "Требуемое кол-во нефти с одной скважины для окупаемости, тыс.бар.: 111.111\n"
     ]
    }
   ],
   "source": [
    "print('Затраты на скважину, млн.руб.:', round(BUDGET_PER_WELL/10**6, 6))\n",
    "print('Требуемое кол-во нефти с одной скважины для окупаемости, тыс.бар.:', round(MIN_VALUE_PRODUCT, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7407025",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font size=\"4\"><b>✔️ Комментарий ревьюера</b></font>\n",
    "    <br /> \n",
    "    <font size=\"3\", color = \"black\">\n",
    "<br />\n",
    "Расчёт верный"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7ec78aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Регион № 1 - отклонение ср. значения запасов скважины от окупаемости, тыс.бар.: -19.033\n",
      "Регион № 2 - отклонение ср. значения запасов скважины от окупаемости, тыс.бар.: -42.388\n",
      "Регион № 3 - отклонение ср. значения запасов скважины от окупаемости, тыс.бар.: -16.227\n",
      "\n",
      "Регион № 2.1 - отклонение ср. значения запасов скважины от окупаемости, тыс.бар.: -43.765\n",
      "Регион № 2.2 - отклонение ср. значения запасов скважины от окупаемости, тыс.бар.: -41.405\n"
     ]
    }
   ],
   "source": [
    "# функция вычисления отклонения среднего значения запасов от значения окупаемости\n",
    "def calc_deviation_stock(ds, title=''):\n",
    "    deviation = round(ds.mean() - MIN_VALUE_PRODUCT, 3)\n",
    "    print(f'{title} - отклонение ср. значения запасов скважины от окупаемости, тыс.бар.:', deviation)\n",
    "\n",
    "# Отклонение среднего значения разведанных запасов по региону от значения запасов для окупаемости\n",
    "calc_deviation_stock(target1, 'Регион № 1')\n",
    "calc_deviation_stock(target2, 'Регион № 2')\n",
    "calc_deviation_stock(target3, 'Регион № 3')\n",
    "print()\n",
    "calc_deviation_stock(target2_1, 'Регион № 2.1')\n",
    "calc_deviation_stock(target2_2, 'Регион № 2.2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db313f2",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font size=\"4\"><b>✔️ Комментарий ревьюера</b></font>\n",
    "    <br /> \n",
    "    <font size=\"3\", color = \"black\">\n",
    "<br />\n",
    "Молодец, что сравниваешь со средним таргетом, а не средним предсказанием. Тут у многих студентов логическая ошибка."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ebe7e1",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<font size=\"4\"><b>⚠️ Комментарий ревьюера</b></font>\n",
    "    <br /> \n",
    "    <font size=\"3\", color = \"black\">\n",
    "<br />\n",
    "<u>Контрольный вопрос:</u>\n",
    "\n",
    "При этом можно посмотреть, что средние таргеты очень близки средним предсказаниям во всех регионах, будь там высокое или низкое значение RMSE. То есть получается, что RMSE может быть высоким, а модель всё равно быть качественной? Или близость среднего предсказания среднему таргету не говорит о качестве модели?\n",
    "    </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4380554",
   "metadata": {},
   "source": [
    "<div style=\"background: #B0E0E6; padding: 5px; border: 1px solid SteelBlue; border-radius: 5px;\">\n",
    "    <font color='4682B4'><u><b>КОММЕНТАРИЙ СТУДЕНТА</b></u></font>\n",
    "    <br />\n",
    "    <font color='4682B4'>Чем больше RMSE, тем больше разница между прогнозируемыми и наблюдаемыми значениями. Разница между не средними значениям выборок (хотя часто и по ним можно понять), а суммарная разница по всеми парам значений в выборках и далее по формуле RMSE.</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5e509a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5139710435510807 37.5794217150813\n",
      "0.005410871086027669 0.893099286775617\n",
      "0.0808131591505088 40.02970873393434\n"
     ]
    }
   ],
   "source": [
    "# если смотреть на разницу средних значений зависимость не всегда видна из-за взаимокомпенсирующих выбросов\n",
    "print((predict1.mean()-target1.mean()), mean_squared_error(target1, predict1) ** 0.5)\n",
    "print((predict2.mean()-target2.mean()), mean_squared_error(target2, predict2) ** 0.5)\n",
    "print((predict3.mean()-target3.mean()), mean_squared_error(target3, predict3) ** 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3ee12b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44.833 44.833\n",
      "28.818396901979124\n"
     ]
    }
   ],
   "source": [
    "# если смотреть на разницу пар значений самих выборок всё сразу понятно\n",
    "actual= [100, 53, 44, 47, 48, 48, 46, 43, 32, 27, 26, 24]\n",
    "predict = [37, 40, 46, 44, 46, 50, 45, 44, 34, 30, 22, 100]\n",
    "\n",
    "print(round(sum(actual)/len(predict), 3), round(sum(predict)/len(predict), 3))\n",
    "print(mean_squared_error(actual, predict) ** 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a333a4",
   "metadata": {},
   "source": [
    "### Выводы по этапу подготовки расчёта прибыли"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279a4303",
   "metadata": {},
   "source": [
    "- в каждом регионе средний запас сырья скважины меньше необходимого для безубыточной добычи на 19, 42.4, 16.2 тыс.бар.\n",
    "- на основании предыдущего заключения можно отметить самую высокую убыточность разработки всех скважин в регионе № 2\n",
    "- для получения прибыли будем исследовать в каждом регионе только 500 скважин, из которых выберем 200 самых прибыльных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5a00a1",
   "metadata": {},
   "source": [
    "## Функция для расчёта прибыли по выбранным скважинам и предсказаниям модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "db7d0c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция расчёта прибыли с заданным в SELECTED_WELLS количеством самых \"богатых\" скважин региона\n",
    "def calc_profit(target, predictions):\n",
    "    target = pd.Series(target).reset_index(drop=True)\n",
    "    predict = pd.Series(predictions).reset_index(drop=True)\n",
    "    predict_sorted = predict.sort_values(ascending=False)\n",
    "    \n",
    "    # выбранные скважины с максимальными предсказанными значениями запасов \n",
    "    selected = target[predict_sorted.index][:SELECTED_WELLS]\n",
    "    \n",
    "    # selected.sum() - целевое значение объёма сырья, соответствующее предсказаниям\n",
    "    profit = selected.sum()*REVENUE_PRODUCT - BUDGET_REGION\n",
    "    \n",
    "    return profit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28cc048",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font size=\"4\"><b>✔️ Комментарий ревьюера</b></font>\n",
    "    <br /> \n",
    "    <font size=\"3\", color = \"black\">\n",
    "<br />\n",
    "Не знаю понимал ли ты что будет, если не сделать в первых строках функции сброс индексов, но в любом случае здорово, что смог избежать бага, на который попадаются почти все студенты! Его описание я в конце работы на всякий случай оставлю."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f850eeb",
   "metadata": {},
   "source": [
    "<div style=\"background: #B0E0E6; padding: 5px; border: 1px solid SteelBlue; border-radius: 5px;\">\n",
    "    <font color='4682B4'><u><b>КОММЕНТАРИЙ СТУДЕНТА</b></u></font>\n",
    "    <br />\n",
    "    <font color='4682B4'>Пришлось разобраться, т.к. без этого не работало --> \"KeyError: \"Passing list-likes to .loc or [] with any missing labels is no longer supported. The following labels were missing: Int64Index([ 9317,   219, 10015, 11584,  4296,\\n            ...\\n            14272, 23129, 21875, 14503, 20881],\\n           dtype='int64', length=18853).\".</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a46286",
   "metadata": {},
   "source": [
    "### Прибыль для полученного объёма сырья с лучших скважин"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bbe08139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Прибыль с 200 лучших скважин ==\n",
      "Регион № 1, млрд.руб.:  3.320826043\n",
      "Регион № 2, млрд.руб.:  2.415086697\n",
      "Регион № 3, млрд.руб.:  2.710349964\n",
      "\n",
      "Регион № 2_1, млрд.руб.:  2.128967464\n",
      "Регион № 2_2, млрд.руб.:  2.415086697\n"
     ]
    }
   ],
   "source": [
    "def former_profit(target, predictions, region='__'):  \n",
    "    print(f'Регион № {region}, млрд.руб.: ',\n",
    "          round(calc_profit(target, predictions)/10**9, 9))\n",
    "\n",
    "print(f'== Прибыль с {SELECTED_WELLS} лучших скважин ==')\n",
    "\n",
    "former_profit(target1, predict1, '1')\n",
    "former_profit(target2, predict2, '2')\n",
    "former_profit(target3, predict3, '3')\n",
    "print()\n",
    "former_profit(target2_1, predict2_1, '2_1')\n",
    "former_profit(target2_2, predict2_2, '2_2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f957a9e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font size=\"4\"><b>✔️ Комментарий ревьюера</b></font>\n",
    "    <br /> \n",
    "    <font size=\"3\", color = \"black\">\n",
    "<br />\n",
    "Мы сейчас видим, что во всех регионах прибыль. А вывод, что каждый регион имеет прибыль, на самом деле, для нас очень важен. И пока что не так важно где больше, это мы потом с помощью бутстрапа ещё поисследуем, а сейчас важно именно то, что гипотетически все в плюсе.<br>\n",
    "\n",
    "Дело в том, что на текущем этапе, когда мы ещё не знаем что получится с помощью бутстрапа, мы уже можем оценить насколько хорошая картина нас может ждать. Ранее мы сравнили средние запасы регионов с точкой безубыточности, и увидели, что каждый регион в среднем убыточен. Если бы мы и здесь увидели убытки, то дальнейшая работа была бы бессмысленной. Зачем нам что-то считать, если у нас даже в лучшем случае убыток? А раз у нас возможна прибыль, то смысл есть, мы делаем качественную осмысленную работу, наша модель для бизнеса может быть полезна.<br>\n",
    "\n",
    "В реальных проектах важно как можно раньше понять движемся ли мы в верном направлении или надо что-то менять. Потому что тратить время и деньги впустую - не лучшая затея."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ce633c",
   "metadata": {},
   "source": [
    "Наблюдение:\n",
    "\n",
    "- наибольшая прибыль в регионе №1, следом регион №3\n",
    "- наименьшая прибыль в регионе №2\n",
    "- прибыль подмножества №2.2 одинакова с регионом №2 в целом, значит все 200 самых \"богатых\" скважин региона в этом подмножестве "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ecc674",
   "metadata": {},
   "source": [
    "## Расчёт прибыли и рисков "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3014165",
   "metadata": {},
   "source": [
    "Применим технику Bootstrap с 1000 выборок, чтобы найти:\n",
    "\n",
    "- распределение прибыли\n",
    "- среднюю прибыль\n",
    "- 95% доверительный интервал\n",
    "- 0,025 и 0,975 квантили распределения прибыли\n",
    "- риск убытков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dbbde7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap(target, predictions, title=''):  \n",
    "    values = []\n",
    "    state = RandomState(12345)\n",
    "    for i in range(1000):\n",
    "        target_subsample = target.sample(n=TESTED_WELLS, replace=True, random_state=state)\n",
    "        predict_subsample = predictions[target_subsample.index]\n",
    "        values.append(calc_profit(target_subsample, predict_subsample))\n",
    "    \n",
    "    values = pd.Series(values)\n",
    "    lower = values.quantile(QUANTILE_LOW)\n",
    "    higher = values.quantile(QUANTILE_HIGH)\n",
    "    conf_int1, conf_int2 = st.t.interval(CONFIDENCE_LEVEL, df=len(values)-1,\n",
    "                                         loc=values.mean(), scale=values.sem())\n",
    "    \n",
    "    print(f'== {title} =')\n",
    "    print('Ожидаемая средняя прибыль, млн.руб.:', round(values.mean()/10**6, 6))\n",
    "    print(f'95% доверительный интервал среднего, млн.руб.: {round(conf_int1/10**6, 6), round(conf_int2/10**6, 6)}')\n",
    "    print('Квантиль 2,5% распределения прибыли, млн.руб.: ', round(lower/10**6, 6))\n",
    "    print('Квантиль 97,5% распределения прибыли, млн.руб.:', round(higher/10**6, 6))\n",
    "    print('Риск убытков, %:', round((values < 0).mean() * 100, 2))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "58c01772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Регион № 1 =\n",
      "Ожидаемая средняя прибыль, млн.руб.: 396.164985\n",
      "95% доверительный интервал среднего, млн.руб.: (379.620315, 412.709654)\n",
      "Квантиль 2,5% распределения прибыли, млн.руб.:  -111.215546\n",
      "Квантиль 97,5% распределения прибыли, млн.руб.: 909.766942\n",
      "Риск убытков, %: 6.9\n",
      "\n",
      "== Регион № 2 =\n",
      "Ожидаемая средняя прибыль, млн.руб.: 456.045106\n",
      "95% доверительный интервал среднего, млн.руб.: (443.147249, 468.942963)\n",
      "Квантиль 2,5% распределения прибыли, млн.руб.:  33.820509\n",
      "Квантиль 97,5% распределения прибыли, млн.руб.: 852.289454\n",
      "Риск убытков, %: 1.5\n",
      "\n",
      "== Регион № 3 =\n",
      "Ожидаемая средняя прибыль, млн.руб.: 404.403867\n",
      "95% доверительный интервал среднего, млн.руб.: (387.445797, 421.361936)\n",
      "Квантиль 2,5% распределения прибыли, млн.руб.:  -163.350413\n",
      "Квантиль 97,5% распределения прибыли, млн.руб.: 950.359575\n",
      "Риск убытков, %: 7.6\n",
      "\n",
      "== Регион № 2.1 =\n",
      "Ожидаемая средняя прибыль, млн.руб.: 286.080019\n",
      "95% доверительный интервал среднего, млн.руб.: (273.104061, 299.055977)\n",
      "Квантиль 2,5% распределения прибыли, млн.руб.:  -139.149452\n",
      "Квантиль 97,5% распределения прибыли, млн.руб.: 673.794593\n",
      "Риск убытков, %: 9.7\n",
      "\n",
      "== Регион № 2.2 =\n",
      "Ожидаемая средняя прибыль, млн.руб.: 510.887321\n",
      "95% доверительный интервал среднего, млн.руб.: (498.289411, 523.48523)\n",
      "Квантиль 2,5% распределения прибыли, млн.руб.:  110.582878\n",
      "Квантиль 97,5% распределения прибыли, млн.руб.: 911.094731\n",
      "Риск убытков, %: 0.6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bootstrap(target1.reset_index(drop=True), predict1, title='Регион № 1')\n",
    "bootstrap(target2.reset_index(drop=True), predict2, title='Регион № 2')\n",
    "bootstrap(target3.reset_index(drop=True), predict3, title='Регион № 3')\n",
    "\n",
    "bootstrap(target2_1.reset_index(drop=True), pd.Series(predict2_1), title='Регион № 2.1')\n",
    "bootstrap(target2_2.reset_index(drop=True), pd.Series(predict2_2), title='Регион № 2.2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2efc9e45",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<font size=\"4\"><b>⚠️ Комментарий ревьюера</b></font>\n",
    "    <br /> \n",
    "    <font size=\"3\", color = \"black\">\n",
    "<br />\n",
    "<u>Контрольный вопрос:</u>\n",
    "\n",
    "В чём разница между t-интервалом и интервала по квантилям? И какой из низ по идее запрашивает описание проекта?\n",
    "\n",
    "Просто многие студенты вычисляют оба только потому что не понимают что от них хотят, вот мы и проверим понимание у тебя )\n",
    "    </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cbaaf7b",
   "metadata": {},
   "source": [
    "<div style=\"background: #B0E0E6; padding: 5px; border: 1px solid SteelBlue; border-radius: 5px;\">\n",
    "    <font color='4682B4'><u><b>КОММЕНТАРИЙ СТУДЕНТА</b></u></font>\n",
    "    <br />\n",
    "    <font color='4682B4'>В настоящем задании: \"5.2. Найдите среднюю прибыль, 95%-й доверительный интервал и риск убытков...\" В задании 3.6 спринта: \"Постройте 95%-й доверительный интервал для среднего чека мармелада в интернет-магазине «Ползучая тянучка»...confidence_interval = st.t.interval(0.95, len(sample)-1, sample.mean(), sample.sem())\". Думаю в текущем задании нужно сделать, как и в 3.6. Иначе я буду жаловаться:).\n",
    "    95% доверительный интервал для среднего значения прибыли - интервал значений с 95% доверительной вероятностью перекрывающий часть диапазона распределения возможных средних значений прибыли, вокруг истинного среднего значения.\n",
    "    Квантили 2,5% и 97,5% в настоящей работе задают доверительный интервал просто значений прибыли на интервале распределения всех значений прибыли. На всякий случай, чтобы зря не жаловаться:)\n",
    "    </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a31516",
   "metadata": {},
   "source": [
    "Наблюдение:\n",
    "\n",
    "- требуемый уровень риска убытков есть только у региона №2 и подмножества №2.2\n",
    "- наибольшая ожидаемая средняя прибыль в регионе №2 (456 млн.руб.)\n",
    "- ожидаемая средняя прибыль в регионе №3 (404 млн.руб.), регионе №1 (396 млн.руб.)\n",
    "- средняя прибыль со скважин подмножества №2.2 (510 млн.руб.) больше чем в самом регионе №2 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8fc58fd",
   "metadata": {},
   "source": [
    "### Выбор региона для разработки скважин"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52431158",
   "metadata": {},
   "source": [
    "- регион №2 (geo_data_1.csv) единственный подходящий под требование \"уровень риска менее 2,5%\"\n",
    "- если есть возможность локализовать скважины подмножества №2.2 из региона №2 это ещё больше улучшит показатели риска и средней прибыли"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560aa690",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<font size=\"4\">🍕<b> Комментарий ревьюера</b></font>\n",
    "    <br /> \n",
    "    <font size=\"3\", color = \"black\">\n",
    "<br />\n",
    "Подведём итоги. В целом всё очень даже хорошо, критических недочётов нет. Всё что жду - ответы на 3 контрольных вопроса, после которых принимаю работу."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c947f1",
   "metadata": {},
   "source": [
    "## Общий вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590256aa",
   "metadata": {},
   "source": [
    "Предобработка и анализ данных:\n",
    "\n",
    "- регион №1 (geo_data_0.csv):\n",
    "    \n",
    "    - причудливые распределения, корреляции и диаграммы рассеяния\n",
    "    - корреляция между 'f0' и 'f1' около 0,5; eсть корреляции с 'product'\n",
    "    - корреляция 'f2' c 'product' около 0,5\n",
    "    \n",
    "- регион №2 (geo_data_1.csv):\n",
    "    \n",
    "    - датафрейм df2 легко можно разделить на два подмножества по смежным категориям признака 'product'\n",
    "    - после разделения:\n",
    "        - у признака 'f0' нормальное распределение\n",
    "        - исчезают корреляции между 'f0', 'f1', 'product'\n",
    "    - признак 'f2' укрупнённо принимает категориальный характер и равномерное распределение\n",
    "    - признак 'product' имеет не интервальный, а категориальный характер и равномерное распределение\n",
    "    - корреляция 'f2' c 'product' около 1\n",
    "    \n",
    "- регион №3 (geo_data_2.csv):\n",
    "\n",
    "    - образцовое распределение данных признаков f0, f1, f2\n",
    "    - корреляция 'f2' c 'product' около 0,5\n",
    "\n",
    "\n",
    "Обучение и проверка модели:\n",
    "\n",
    "- в регионе №3 наибольшие запасы, за ним регион №1 с небольшим отставанием\n",
    "- для регионов №1 и №3 самые большие значения среднеквадратичной ошибки RMSE: 37.6 и 40\n",
    "- меньше всего запасов в регионе №2, но среднеквадратичная ошибка менее 1\n",
    "- а у подмножеств №2.1 и №2.2 среднеквадратичная ошибка менее 0,14 \n",
    "\n",
    "\n",
    "Подготовка расчёта прибыли:\n",
    "\n",
    "- в каждом регионе средний запас сырья скважины меньше необходимого для безубыточной добычи на 19, 42.4, 16.2 тыс.бар.\n",
    "- на основании предыдущего заключения можно отметить самую высокую убыточность разработки всех скважин в регионе № 2\n",
    "- для получения прибыли будем исследовать в каждом регионе только 500 скважин, из которых выберем 200 самых \n",
    "\n",
    "\n",
    "Расчёт прибыли для полученного объёма нефти с лучших скважин:\n",
    "\n",
    "- наибольшая прибыль в регионе №1, следом регион №3\n",
    "- наименьшая прибыль в регионе №2\n",
    "- прибыль подмножества №2.2 одинакова с регионом №2 в целом, значит все 200 самых \"богатых\" скважин региона в этом подмножестве \n",
    "\n",
    "\n",
    "Расчёт прибыли и риска методом \"Bootstrap\":\n",
    "\n",
    "- требуемый уровень риска убытков есть только у региона №2 и подмножества №2.2\n",
    "- наибольшая ожидаемая средняя прибыль в регионе №2 (456 млн.руб.)\n",
    "- ожидаемая средняя прибыль в регионе №3 (404 млн.руб.), регионе №1 (396 млн.руб.)\n",
    "- средняя прибыль со скважин подмножества №2.2 (510 млн.руб.) больше чем в самом регионе №2 \n",
    "\n",
    "\n",
    "ИТОГ:\n",
    "- регион №2 (geo_data_1.csv) лучший из трёх и единственный подходящий по заданию для разработки нефтяных скважин\n",
    "- если есть возможность локализовать скважины подмножества №2.2 из региона №2 это ещё больше улучшит показатели риска и средней прибыли"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1f45f9",
   "metadata": {},
   "source": [
    "#### **ПРИЛОЖЕНИЕ**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ee6852",
   "metadata": {},
   "source": [
    "Указанные выше выводы сделаны в результате следующих проделанных действий (кратко):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01cc631d",
   "metadata": {},
   "source": [
    "**Краткое описание:**\n",
    "\n",
    "- файл данных:\n",
    "    - 'https://code.s3.yandex.net/datasets/geo_data_0.csv'\n",
    "    - 'https://code.s3.yandex.net/datasets/geo_data_1.csv'\n",
    "    - 'https://code.s3.yandex.net/datasets/geo_data_2.csv'\n",
    "- в качестве разделителя в csv файле применён знак табуляции (',')\n",
    "- размерность: 14 столбцов на 10000 строк\n",
    "- типы данных: float64(3), int64(8), object(3)\n",
    "\n",
    "**Описание типов и распределеления данных:**\n",
    "\n",
    "- df1 (geo_data_0.csv):\n",
    "\t- id      — [object]  — \n",
    "    - f0      — [float64] — вид сложения нескольких нормальных распределений\n",
    "    - f1      — [float64] — вид сложения нескольких нормальных распределений\n",
    "    - f2      — [float64] — нормальное распределение\n",
    "    - product — [float64] — распределение смешанного вида (нормальное и равномерное)\n",
    "    \n",
    "    - корреляция между 'f0' и 'f1' около 0,5; eсть корреляции с 'product'\n",
    "    - корреляция 'f2' c 'product' около 0,5\n",
    "    \n",
    "- df2 (geo_data_1.csv):\n",
    "\t- id      — [object]  — \n",
    "    - f0      — [float64] — имеет вид сложения двух нормальных распределений\n",
    "    - f1      — [float64] — нормальное распределение\n",
    "    - f2      — [float64] — укрупнённо принимает категориальный характер и равномерное распределение\n",
    "    - product — [float64] — имеет не интервальный, а категориальный характер и равномерное распределение\n",
    "    \n",
    "    - датафрейм df2 легко можно разделить на два подмножества по смежным категориям признака 'product'\n",
    "    - после разделения:\n",
    "        - у признака 'f0' нормальное распределение\n",
    "        - исчезают корреляции между 'f0', 'f1', 'product'\n",
    "    - корреляция 'f2' c 'product' около 1\n",
    "    \n",
    "- df3 (geo_data_2.csv):\n",
    "\t- id      — [object]  — \n",
    "    - f0      — [float64] — нормальное распределение\n",
    "    - f1      — [float64] — нормальное распределение\n",
    "    - f2      — [float64] — нормальное распределение\n",
    "    - product — [float64] — распределение смешанного вида (нормальное и равномерное)\n",
    "    \n",
    "    - корреляция 'f2' c 'product' около 0,5\n",
    "\n",
    "**Изменение типов данных:**\n",
    "\n",
    "- нет\n",
    "\n",
    "**Пропуски, аномалии, дубликаты:**\n",
    "\n",
    "пропуски:\n",
    "\n",
    "- нет\n",
    "    \n",
    "аномалии:\n",
    "    \n",
    "- нет\n",
    "\n",
    "количество уникальных значений в столбцах:\n",
    "\n",
    "- id      — 99990/100000 (df1), 99996/100000 (df2, df3)\n",
    "- f0      — 100000/100000\n",
    "- f1      — 100000/100000\n",
    "- f2      — 100000/100000\n",
    "- product — 100000/100000 (df1, df3), 12/100000 (df2)\n",
    "\n",
    "количество дубликатов между столбцами:\n",
    "\n",
    "- не проверял\n",
    "\n",
    "количество дубликатов строк с выборочными столбцами:\n",
    "\n",
    "- id, product: 0\n",
    "\n",
    "\n",
    "**Прочее**:\n",
    "\n",
    "- дубли в столбце 'id', возможно, возникли в результае коллизий хеш-функции\n",
    "\n",
    "**Добавлено типов данных:**\n",
    "    \n",
    "- нет\n",
    "   \n",
    "**Удалено типов данных:**\n",
    "    \n",
    "- столбец \"id\"\n",
    "\n",
    "**Категоризация данных:**\n",
    "    \n",
    "- нет\n",
    "\n",
    "**Проверка гипотез:**\n",
    "    \n",
    "- улучшение результатов при разделении массива данные из региона № 2 на два подмножества\n",
    "\n",
    "**Итоговая структура данных:**\n",
    "    \n",
    "- без изменений\n",
    " \n",
    "**Общий вывод**\n",
    "\n",
    "**Трудоёмкость:**\n",
    "   \n",
    "- на выполнение работы затрачено полных 5 дней без перерыров\n",
    "- дополнительно __ дня на исправление замечаний после ревью №1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21acd72",
   "metadata": {},
   "source": [
    "## Чек-лист готовности проекта"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121913fc",
   "metadata": {},
   "source": [
    "Поставьте 'x' в выполненных пунктах. Далее нажмите Shift+Enter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0029edb6",
   "metadata": {},
   "source": [
    "- [x]  Jupyter Notebook открыт\n",
    "- [x]  Весь код выполняется без ошибок\n",
    "- [x]  Ячейки с кодом расположены в порядке исполнения\n",
    "- [x]  Выполнен шаг 1: данные подготовлены\n",
    "- [x]  Выполнен шаг 2: модели обучены и проверены\n",
    "    - [x]  Данные корректно разбиты на обучающую и валидационную выборки\n",
    "    - [x]  Модели обучены, предсказания сделаны\n",
    "    - [x]  Предсказания и правильные ответы на валидационной выборке сохранены\n",
    "    - [x]  На экране напечатаны результаты\n",
    "    - [x]  Сделаны выводы\n",
    "- [x]  Выполнен шаг 3: проведена подготовка к расчёту прибыли\n",
    "    - [x]  Для всех ключевых значений созданы константы Python\n",
    "    - [x]  Посчитано минимальное среднее количество продукта в месторождениях региона, достаточное для разработки\n",
    "    - [x]  По предыдущему пункту сделаны выводы\n",
    "    - [x]  Написана функция расчёта прибыли\n",
    "- [x]  Выполнен шаг 4: посчитаны риски и прибыль\n",
    "    - [x]  Проведена процедура *Bootstrap*\n",
    "    - [x]  Все параметры бутстрепа соответствуют условию\n",
    "    - [x]  Найдены все нужные величины\n",
    "    - [x]  Предложен регион для разработки месторождения\n",
    "    - [x]  Выбор региона обоснован"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e93a6c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c62164c5",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Дополнительный-инструментарий\" data-toc-modified-id=\"Дополнительный-инструментарий-0.1\"><span class=\"toc-item-num\">0.1&nbsp;&nbsp;</span>Дополнительный инструментарий</a></span></li><li><span><a href=\"#Загрузка-и-подготовка-данных\" data-toc-modified-id=\"Загрузка-и-подготовка-данных-0.2\"><span class=\"toc-item-num\">0.2&nbsp;&nbsp;</span>Загрузка и подготовка данных</a></span></li><li><span><a href=\"#Первый-&quot;взгляд&quot;\" data-toc-modified-id=\"Первый-&quot;взгляд&quot;-0.3\"><span class=\"toc-item-num\">0.3&nbsp;&nbsp;</span>Первый \"взгляд\"</a></span><ul class=\"toc-item\"><li><span><a href=\"#Первый-регион\" data-toc-modified-id=\"Первый-регион-0.3.1\"><span class=\"toc-item-num\">0.3.1&nbsp;&nbsp;</span>Первый регион</a></span></li><li><span><a href=\"#Второй-регион\" data-toc-modified-id=\"Второй-регион-0.3.2\"><span class=\"toc-item-num\">0.3.2&nbsp;&nbsp;</span>Второй регион</a></span><ul class=\"toc-item\"><li><span><a href=\"#Подмножество-1\" data-toc-modified-id=\"Подмножество-1-0.3.2.1\"><span class=\"toc-item-num\">0.3.2.1&nbsp;&nbsp;</span>Подмножество 1</a></span></li><li><span><a href=\"#Подмножество-2\" data-toc-modified-id=\"Подмножество-2-0.3.2.2\"><span class=\"toc-item-num\">0.3.2.2&nbsp;&nbsp;</span>Подмножество 2</a></span></li></ul></li><li><span><a href=\"#Третий-регион\" data-toc-modified-id=\"Третий-регион-0.3.3\"><span class=\"toc-item-num\">0.3.3&nbsp;&nbsp;</span>Третий регион</a></span></li><li><span><a href=\"#Вывод\" data-toc-modified-id=\"Вывод-0.3.4\"><span class=\"toc-item-num\">0.3.4&nbsp;&nbsp;</span>Вывод</a></span></li></ul></li></ul></li><li><span><a href=\"#Обучение-и-проверка-модели\" data-toc-modified-id=\"Обучение-и-проверка-модели-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Обучение и проверка модели</a></span></li><li><span><a href=\"#Подготовка-к-расчёту-прибыли\" data-toc-modified-id=\"Подготовка-к-расчёту-прибыли-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Подготовка к расчёту прибыли</a></span><ul class=\"toc-item\"><li><span><a href=\"#Расчёт-и-сравнение-достаточного-объёма-сырья-для-безубыточной-разработки-новой-скважины\" data-toc-modified-id=\"Расчёт-и-сравнение-достаточного-объёма-сырья-для-безубыточной-разработки-новой-скважины-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Расчёт и сравнение достаточного объёма сырья для безубыточной разработки новой скважины</a></span></li><li><span><a href=\"#Выводы-по-этапу-подготовки-расчёта-прибыли\" data-toc-modified-id=\"Выводы-по-этапу-подготовки-расчёта-прибыли-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Выводы по этапу подготовки расчёта прибыли</a></span></li></ul></li><li><span><a href=\"#Функция-для-расчёта-прибыли-по-выбранным-скважинам-и-предсказаниям-модели\" data-toc-modified-id=\"Функция-для-расчёта-прибыли-по-выбранным-скважинам-и-предсказаниям-модели-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Функция для расчёта прибыли по выбранным скважинам и предсказаниям модели</a></span><ul class=\"toc-item\"><li><span><a href=\"#Прибыль-для-полученного-объёма-сырья-с-лучших-скважин\" data-toc-modified-id=\"Прибыль-для-полученного-объёма-сырья-с-лучших-скважин-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Прибыль для полученного объёма сырья с лучших скважин</a></span></li></ul></li><li><span><a href=\"#Расчёт-прибыли-и-рисков\" data-toc-modified-id=\"Расчёт-прибыли-и-рисков-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Расчёт прибыли и рисков</a></span><ul class=\"toc-item\"><li><span><a href=\"#Выбор-региона-для-разработки-скважин\" data-toc-modified-id=\"Выбор-региона-для-разработки-скважин-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Выбор региона для разработки скважин</a></span></li></ul></li><li><span><a href=\"#Общий-вывод\" data-toc-modified-id=\"Общий-вывод-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Общий вывод</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#ПРИЛОЖЕНИЕ\" data-toc-modified-id=\"ПРИЛОЖЕНИЕ-5.0.1\"><span class=\"toc-item-num\">5.0.1&nbsp;&nbsp;</span><strong>ПРИЛОЖЕНИЕ</strong></a></span></li></ul></li></ul></li><li><span><a href=\"#Чек-лист-готовности-проекта\" data-toc-modified-id=\"Чек-лист-готовности-проекта-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Чек-лист готовности проекта</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8838ca3",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font size=\"4\"><b>✔️ Комментарий ревьюера</b></font>\n",
    "    <br /> \n",
    "    <font size=\"3\", color = \"black\">\n",
    "<br />    \n",
    "Как и обещал, рассказ об одном очень популярном у студентов баге, которого ты избежал. Большинство студентов как и ты хранят и предсказания, и таргеты, как структуры pandas.Series. Сейчас на небольшом синтетеическом примере покажу что у них получается:\n",
    "<br />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c58cbc8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    3\n",
       "3    3\n",
       "3    3\n",
       "3    3\n",
       "3    3\n",
       "3    3\n",
       "3    3\n",
       "3    3\n",
       "3    3\n",
       "2    2\n",
       "2    2\n",
       "2    2\n",
       "2    2\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# КОД РЕВЬЮЕРА\n",
    "# предположим, у нас есть небольшой сэмпл из 5 предсказаний и 5 соответствующих таргетов\n",
    "_target = pd.Series([2, 2, 3, 3, 3], index=[2, 2, 3, 3, 3])\n",
    "_preds = pd.Series([2, 2, 3, 3, 3], index=[2, 2, 3, 3, 3]).sort_values(ascending=False)\n",
    "\n",
    "\n",
    "# берём таргеты по индексам предсказаний:\n",
    "\n",
    "display(_target.loc[_preds.index])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632e917d",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font size=\"4\"></font>\n",
    "    <font size=\"3\", color = \"black\">\n",
    "Как так? Почему предсказаний 5, а таргетов аж 13? На самом деле, всё очень просто. На примере элементов с индексом и значением 2. Когда мы попросили у пандаса взять таргеты по индексам предсказаний, и у нас и там и там 2 одинаковых элемента, он отнюдь должен вернуть не 2. Он для каждого запрошенного индекса предсказаний выдаёт все таргеты с таким индексом. Таким образом, мы запросили 2 раза элемента с индексом 2 - оба раза пандас отдал нам 2 таких элемента из таргетов - всего 4 элемента. А если бы у нас было и там, и там по 3 одинаковых элемента, то в итоге было бы 9. Логика, надеюсь, ясна. И вот поэтому почти всегда у студентов получается, что когда берёшь таргеты по индексам 500 предсказаний, получают в итоге более чем 500 таргетов. Благодаря бутстрапу в выборках есть идентичные элементы, с одинаковыми индексами, и они каждый раз вот таким образом \"множатся\" при вычислении прибыли.\n",
    "\n",
    "Сделать как у тебя, что одна из структур - не Series, а array (в array индексы повторяться не могут, поэтому проблема не возникает) - не единственное решение, их как минимум на 3 больше:\n",
    "\n",
    "1. На самом деле, если внимательно посмотреть на нашу задачу, то становится понятно, что переменная target_subsample в функции bootstrap нам не нужна. Фактически она используется только для того, чтобы по её индексам взять сэмпл предсказаний. Но мы можем получить сэмпл предсказаний напрямую:\n",
    "\n",
    "`pred_subsample = predictions.sample(n=500, replace=True, random_state=state)`\n",
    "\n",
    "а в функцию расчёта прибыли передать pred_subsample и target (не сэмпл таргетов, а исходный, полный валидационный таргет, 25000 уникальных элементов с неповторяющимися индексами), и тогда получилось бы, что мы сэмплируем предсказания, сортируем их, выбираем 200 лучших, и только после этого по их индексам берём таргеты. Но поскольку таргеты бы были исходные, с уникальными индексами, то запросив один и тот же индекс 2 раза, мы бы в ответ получили 2 одинаковых элемента, а не 4, ошибки бы не было.\n",
    "\n",
    "2. Можно было бы хранить предсказания и таргеты в одном датафрейме и оперировать бы с ним, а не отдельными его колонками. Тогда вообще не надо было бы делать операцию взятия по индексам: применил .sample() ко всему датафрейму, отсортировал по одной колонке, просуммировал первые 200 значений другой. Всё, элементы одной строки датафрейма между собой жёстко связаны, никакого расхождения не может быть, всё корректно.\n",
    "\n",
    "3. Самое \"лобовое\" решение, которое большинство студентов и применяет: .reset_index(drop=True) и для таргетов, и для предсказаний в первых же строках функции расчёта прибыли. Логично: значения сохранились, индексы больше не повторяются, бага не будет:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "86cb54e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    3\n",
       "3    3\n",
       "4    3\n",
       "0    2\n",
       "1    2\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# КОД РЕВЬЮЕРА\n",
    "# предположим, у нас есть небольшой сэмпл из 5 предсказаний и 5 соответствующих таргетов\n",
    "_target = pd.Series([2, 2, 3, 3, 3], index=[2, 2, 3, 3, 3]).reset_index(drop=True)\n",
    "_preds = pd.Series([2, 2, 3, 3, 3], index=[2, 2, 3, 3, 3]).reset_index(drop=True).sort_values(ascending=False)\n",
    "\n",
    "\n",
    "# берём таргеты по индексам предсказаний:\n",
    "\n",
    "display(_target.loc[_preds.index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e0a5dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 3,
    "start_time": "2023-06-04T18:23:50.988Z"
   },
   {
    "duration": 29,
    "start_time": "2023-06-04T18:23:50.993Z"
   },
   {
    "duration": 24,
    "start_time": "2023-06-04T18:23:51.024Z"
   },
   {
    "duration": 30,
    "start_time": "2023-06-04T18:23:51.050Z"
   },
   {
    "duration": 16,
    "start_time": "2023-06-04T18:23:51.082Z"
   },
   {
    "duration": 16,
    "start_time": "2023-06-04T18:23:51.100Z"
   },
   {
    "duration": 11,
    "start_time": "2023-06-04T18:23:51.118Z"
   },
   {
    "duration": 21,
    "start_time": "2023-06-04T18:23:51.131Z"
   },
   {
    "duration": 1592,
    "start_time": "2023-06-04T18:23:51.154Z"
   },
   {
    "duration": 3,
    "start_time": "2023-06-04T18:23:52.748Z"
   },
   {
    "duration": 9,
    "start_time": "2023-06-04T18:23:52.753Z"
   },
   {
    "duration": 1189,
    "start_time": "2023-06-04T18:23:52.764Z"
   },
   {
    "duration": 12625,
    "start_time": "2023-06-04T18:23:53.955Z"
   },
   {
    "duration": 169,
    "start_time": "2023-06-04T18:24:06.583Z"
   },
   {
    "duration": 29,
    "start_time": "2023-06-04T18:24:06.754Z"
   },
   {
    "duration": 33,
    "start_time": "2023-06-04T18:24:06.785Z"
   },
   {
    "duration": 11861,
    "start_time": "2023-06-04T18:24:06.820Z"
   },
   {
    "duration": 79,
    "start_time": "2023-06-04T18:24:18.683Z"
   },
   {
    "duration": 19,
    "start_time": "2023-06-04T18:24:18.764Z"
   },
   {
    "duration": 25,
    "start_time": "2023-06-04T18:24:18.785Z"
   },
   {
    "duration": 7,
    "start_time": "2023-06-04T18:24:18.811Z"
   },
   {
    "duration": 30,
    "start_time": "2023-06-04T18:24:18.819Z"
   },
   {
    "duration": 13,
    "start_time": "2023-06-04T18:24:18.851Z"
   },
   {
    "duration": 13,
    "start_time": "2023-06-04T18:24:18.865Z"
   },
   {
    "duration": 7420,
    "start_time": "2023-06-04T18:24:18.879Z"
   },
   {
    "duration": 7396,
    "start_time": "2023-06-04T18:24:26.301Z"
   },
   {
    "duration": 13169,
    "start_time": "2023-06-04T18:24:33.698Z"
   },
   {
    "duration": 104,
    "start_time": "2023-06-04T18:24:46.869Z"
   },
   {
    "duration": 20,
    "start_time": "2023-06-04T18:24:46.977Z"
   },
   {
    "duration": 49,
    "start_time": "2023-06-04T18:24:46.998Z"
   },
   {
    "duration": 17,
    "start_time": "2023-06-04T18:24:47.049Z"
   },
   {
    "duration": 9,
    "start_time": "2023-06-04T18:24:47.067Z"
   },
   {
    "duration": 680,
    "start_time": "2023-06-04T18:24:47.078Z"
   },
   {
    "duration": 87,
    "start_time": "2023-06-04T18:24:47.760Z"
   },
   {
    "duration": 120,
    "start_time": "2023-06-04T18:24:47.849Z"
   },
   {
    "duration": 18,
    "start_time": "2023-06-04T18:24:47.971Z"
   },
   {
    "duration": 9,
    "start_time": "2023-06-04T18:24:47.991Z"
   },
   {
    "duration": 36,
    "start_time": "2023-06-04T18:24:48.001Z"
   },
   {
    "duration": 14,
    "start_time": "2023-06-04T18:24:48.039Z"
   },
   {
    "duration": 6324,
    "start_time": "2023-06-04T18:24:48.054Z"
   },
   {
    "duration": 10,
    "start_time": "2023-06-04T18:51:03.826Z"
   },
   {
    "duration": 8,
    "start_time": "2023-06-04T18:51:22.728Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "214.433px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
